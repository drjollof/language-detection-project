{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas\n",
    "# !pip install numpy \n",
    "# !pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dataset\n",
    "data = pd.read_csv('language_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minor EDA   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0    0\n",
       "Text          0\n",
       "language      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for the shape of dataset and missing values\n",
    "data.shape\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Text', 'language'], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop unnecessary column\n",
    "data.drop(columns='Unnamed: 0', inplace=True)\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "language\n",
       "Estonian      1000\n",
       "Swedish       1000\n",
       "English       1000\n",
       "Russian       1000\n",
       "Romanian      1000\n",
       "Persian       1000\n",
       "Pushto        1000\n",
       "Spanish       1000\n",
       "Hindi         1000\n",
       "Korean        1000\n",
       "Chinese       1000\n",
       "French        1000\n",
       "Portugese     1000\n",
       "Indonesian    1000\n",
       "Urdu          1000\n",
       "Latin         1000\n",
       "Turkish       1000\n",
       "Japanese      1000\n",
       "Dutch         1000\n",
       "Tamil         1000\n",
       "Thai          1000\n",
       "Arabic        1000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for number of observations per language\n",
    "data['language'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate X and Y features\n",
    "x_data = data[['Text']]\n",
    "y_data = data[['language']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22000, 277720)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extract X features and check new shape\n",
    "vectorizer = CountVectorizer()\n",
    "x_data_vectorized = vectorizer.fit_transform(x_data['Text'])\n",
    "x_data_vectorized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split X and Y data with balanced number of observations in target variable\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data_vectorized, y_data,\n",
    "                                                     test_size= 0.3, \n",
    "                                                     random_state=34, \n",
    "                                                     stratify = y_data\n",
    "                                                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all modules\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix,f1_score\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameter tuning for RF classifier\n",
    "param_grid = {'max_depth': [5, 8, None],\n",
    "              'max_features' : [5, 7, \"auto\"],\n",
    "              'n_estimators': [50, 100, 150],\n",
    "              'min_samples_split': [2, 8]\n",
    "              }\n",
    "\n",
    "new_rf = RandomForestClassifier(random_state= 12)\n",
    "cv = GridSearchCV(estimator=new_rf, \n",
    "                  param_grid= param_grid,\n",
    "                    cv= 5)\n",
    "cv.fit(x_train, y_train['language'])\n",
    "cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify model dictionary\n",
    "models = {\n",
    "     'Logistic Regression' : LogisticRegression(random_state=45),\n",
    "     'Multinomial NB' : MultinomialNB(),\n",
    "     'SVC' : SVC(random_state=21),\n",
    "     'RF Classifier' : RandomForestClassifier(max_features=5,\n",
    "                                              min_samples_split=8,\n",
    "                                              n_estimators=150,\n",
    "                                              random_state=12)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:33<01:40, 33.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "Accuracy : 0.9466666666666667\n",
      "Precision: 0.9597950007946767\n",
      "Recall : 0.9466666666666667\n",
      "F1 score : 0.9490172242528225\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:34<00:28, 14.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial NB\n",
      "Accuracy : 0.9554545454545454\n",
      "Precision: 0.9643046553216775\n",
      "Recall : 0.9554545454545454\n",
      "F1 score : 0.9552240505289885\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [01:37<00:36, 36.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC\n",
      "Accuracy : 0.894090909090909\n",
      "Precision: 0.9196356565331157\n",
      "Recall : 0.894090909090909\n",
      "F1 score : 0.9003272492240816\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [05:48<00:00, 87.11s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF Classifier\n",
      "Accuracy : 0.9409090909090909\n",
      "Precision: 0.9663120721574046\n",
      "Recall : 0.9409090909090909\n",
      "F1 score : 0.932842299313773\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(list(models)))) :\n",
    "    #fit model\n",
    "    model_object = list(models.values())[i]\n",
    "    model = model_object.fit(x_train, y_train['language'])\n",
    "    \n",
    "\n",
    "    #predict and collect metrics\n",
    "    y_predicted = model.predict(x_test)\n",
    "    model_accuracy = accuracy_score(y_test, y_predicted)\n",
    "    model_precision = precision_score(y_test, y_predicted, average= \"weighted\")\n",
    "    model_recall = recall_score(y_test, y_predicted, average= \"weighted\")\n",
    "    model_f1_score = f1_score(y_test, y_predicted, average= \"weighted\" )\n",
    "    \n",
    "    #print metrics\n",
    "    print(list(models.keys())[i])\n",
    "    print(f\"Accuracy : {model_accuracy}\")\n",
    "    print (f\"Precision: {model_precision}\")\n",
    "    print(f\"Recall : {model_recall}\")\n",
    "    print(f\"F1 score : {model_f1_score}\" )\n",
    "    print('=' *35)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNB = MultinomialNB()\n",
    "MNB_model = MNB.fit(x_train, y_train['language'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing model on new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to predict a dataframe of text\n",
    "def predict_dataset(dataset):\n",
    " data_detected = False\n",
    " try: \n",
    "  #try to read as csv\n",
    "  new_test_data = pd.read_csv(dataset + '.csv', delimiter= \",\")\n",
    "  data_detected = True\n",
    " except FileNotFoundError:\n",
    "   try:\n",
    "   #try to read as txt\n",
    "     new_test_data = pd.read_csv(dataset + '.txt', delimiter= \",\")\n",
    "     data_detected = True\n",
    "   \n",
    "   finally:\n",
    "     if data_detected == True:\n",
    "      new_data_x = new_test_data['text']\n",
    "      new_data_y = new_test_data['language']\n",
    "      new_data_vectorized = vectorizer.transform(new_data_x)\n",
    "      new_predictions_NB = MNB_model.predict(new_data_vectorized)\n",
    "      accuracy = accuracy_score(new_data_y, new_predictions_NB)\n",
    "      print(accuracy)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8484848484848485\n"
     ]
    }
   ],
   "source": [
    "\n",
    "predict_dataset('multilingual-100')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to predict a single text\n",
    "def predict_text(text):\n",
    "    text = vectorizer.transform([text])\n",
    "    prediction = MNB_model.predict(text)\n",
    "    print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['French']\n"
     ]
    }
   ],
   "source": [
    "text = \"La musique adoucit les mœurs et inspire l'âme\"\n",
    "predict_text(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
