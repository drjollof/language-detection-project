{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LENOVO\\anaconda3\\python.exe\n",
      "C:\\Users\\LENOVO\\AppData\\Local\\Microsoft\\WindowsApps\\python.exe\n"
     ]
    }
   ],
   "source": [
    "# !pip install pandas\n",
    "# !pip install numpy \n",
    "# !pip install scikit-learn\n",
    "!where python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import seaborn as sns  \n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DATASET OVERVIEW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Text</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>klement gottwaldi surnukeha palsameeriti ning ...</td>\n",
       "      <td>Estonian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>sebes joseph pereira thomas  på eng the jesuit...</td>\n",
       "      <td>Swedish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ถนนเจริญกรุง อักษรโรมัน thanon charoen krung เ...</td>\n",
       "      <td>Thai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>விசாகப்பட்டினம் தமிழ்ச்சங்கத்தை இந்துப் பத்திர...</td>\n",
       "      <td>Tamil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>de spons behoort tot het geslacht haliclona en...</td>\n",
       "      <td>Dutch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>エノが行きがかりでバスに乗ってしまい、気分が悪くなった際に助けるが、今すぐバスを降りたいと運...</td>\n",
       "      <td>Japanese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>tsutinalar i̇ngilizce tsuutina kanadada albert...</td>\n",
       "      <td>Turkish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>müller mox figura centralis circulorum doctoru...</td>\n",
       "      <td>Latin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>برقی بار electric charge تمام زیرجوہری ذرات کی...</td>\n",
       "      <td>Urdu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>シャーリー・フィールドは、サン・ベルナルド・アベニュー沿い市民センターとrtマーティン高校に...</td>\n",
       "      <td>Japanese</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               Text  language\n",
       "0           0  klement gottwaldi surnukeha palsameeriti ning ...  Estonian\n",
       "1           1  sebes joseph pereira thomas  på eng the jesuit...   Swedish\n",
       "2           2  ถนนเจริญกรุง อักษรโรมัน thanon charoen krung เ...      Thai\n",
       "3           3  விசாகப்பட்டினம் தமிழ்ச்சங்கத்தை இந்துப் பத்திர...     Tamil\n",
       "4           4  de spons behoort tot het geslacht haliclona en...     Dutch\n",
       "5           5  エノが行きがかりでバスに乗ってしまい、気分が悪くなった際に助けるが、今すぐバスを降りたいと運...  Japanese\n",
       "6           6  tsutinalar i̇ngilizce tsuutina kanadada albert...   Turkish\n",
       "7           7  müller mox figura centralis circulorum doctoru...     Latin\n",
       "8           8  برقی بار electric charge تمام زیرجوہری ذرات کی...      Urdu\n",
       "9           9  シャーリー・フィールドは、サン・ベルナルド・アベニュー沿い市民センターとrtマーティン高校に...  Japanese"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import dataset\n",
    "pd.set_option('display.max_rows', None)\n",
    "data = pd.read_csv('datasets\\\\language_dataset.csv')\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0    0\n",
       "Text          0\n",
       "language      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for the shape of dataset and missing values\n",
    "data.shape\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Text', 'language'], dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop unnecessary column\n",
    "data.drop(columns='Unnamed: 0', inplace=True)\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "language\n",
       "Estonian      1000\n",
       "Swedish       1000\n",
       "English       1000\n",
       "Russian       1000\n",
       "Romanian      1000\n",
       "Persian       1000\n",
       "Pushto        1000\n",
       "Spanish       1000\n",
       "Hindi         1000\n",
       "Korean        1000\n",
       "Chinese       1000\n",
       "French        1000\n",
       "Portuguese    1000\n",
       "Indonesian    1000\n",
       "Urdu          1000\n",
       "Latin         1000\n",
       "Turkish       1000\n",
       "Japanese      1000\n",
       "Dutch         1000\n",
       "Tamil         1000\n",
       "Thai          1000\n",
       "Arabic        1000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for number of observations per language\n",
    "data.replace('Portugese', 'Portuguese', inplace=True)\n",
    "data['language'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FEATURE EXTRACTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate X and Y features\n",
    "x_data = data['Text']\n",
    "y_data = data['language']\n",
    "\n",
    "#split X and Y data with balanced number of observations in target variable\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data,\n",
    "                                                     test_size= 0.3, \n",
    "                                                     random_state=34, \n",
    "                                                     stratify = y_data\n",
    "                                                     )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15400, 1305683)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#extract X features and check new shape\n",
    "vectorizer = CountVectorizer(analyzer = 'char' , ngram_range=(1,4))\n",
    "x_train_vectorized = vectorizer.fit_transform(x_train)\n",
    "x_train_vectorized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check vocabulary list\n",
    "print(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MODEL TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all modules\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix,f1_score\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specify model dictionary\n",
    "models = {\n",
    "     'Logistic Regression' : LogisticRegression(),\n",
    "     'Multinomial NB' : MultinomialNB(),\n",
    "     'SVC' : SVC(),\n",
    "     'RF Classifier' : RandomForestClassifier()\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train and evaluate train metrics\n",
    "print('TRAINING SET METRICS')\n",
    "for i in tqdm(range(len(list(models)))) :\n",
    "    #fit model\n",
    "    model_object = list(models.values())[i]\n",
    "    model = model_object.fit(x_train_vectorized, y_train)\n",
    "\n",
    "\n",
    "    #predict and collect metrics\n",
    "    y_train_predicted = model.predict(x_train_vectorized)\n",
    "\n",
    "\n",
    "    model_train_accuracy = accuracy_score(y_train, y_train_predicted)\n",
    "    model_train_precision = precision_score(y_train, y_train_predicted, average= \"weighted\")\n",
    "    model_train_recall = recall_score(y_train, y_train_predicted, average= \"weighted\")\n",
    "    model_train_f1_score = f1_score(y_train, y_train_predicted, average= \"weighted\" )\n",
    "\n",
    "\n",
    "    #print metrics\n",
    "    print(list(models.keys())[i])\n",
    "    print(f\"Accuracy : {model_train_accuracy:.4f}\")\n",
    "    print (f\"Precision: {model_train_precision:.4f}\")\n",
    "    print(f\"Recall : {model_train_recall:.4f}\")\n",
    "    print(f\"F1 score : {model_train_f1_score:.4f}\" )\n",
    "    print('=' *35)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train and evaluate test metrics\n",
    "print('TESTING SET METRICS')\n",
    "for i in tqdm(range(len(list(models)))) :\n",
    "    #fit model\n",
    "    model_object = list(models.values())[i]\n",
    "    model = model_object.fit(x_train_vectorized, y_train)\n",
    "\n",
    "\n",
    "    #predict and collect metrics\n",
    "    x_test_vectorized = vectorizer.transform(x_test)\n",
    "    y_test_predicted = model.predict(x_test_vectorized)\n",
    "\n",
    "\n",
    "    model_test_accuracy = accuracy_score(y_test, y_test_predicted)\n",
    "    model_test_precision = precision_score(y_test, y_test_predicted, average= \"weighted\")\n",
    "    model_test_recall = recall_score(y_test, y_test_predicted, average= \"weighted\")\n",
    "    model_test_f1_score = f1_score(y_test, y_test_predicted, average= \"weighted\" )\n",
    "\n",
    "    #print metrics\n",
    "    print(list(models.keys())[i])\n",
    "    print(f\"Accuracy : {model_test_accuracy:.4f}\")\n",
    "    print (f\"Precision: {model_test_precision:.4f}\")\n",
    "    print(f\"Recall : {model_test_recall:.4f}\")\n",
    "    print(f\"F1 score : {model_test_f1_score:.4f}\" )\n",
    "    print('=' *35)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TRAIN FINAL MODEL AND EVALUATE ON NEW DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to plot confusion matrix\n",
    "def confusion(predicted_y, y):\n",
    "  plt.figure(figsize=(15,10))\n",
    "  languages = np.unique(y)\n",
    "  cm2 = confusion_matrix(y, predicted_y, labels= languages)\n",
    "  sns.heatmap(cm2, annot=True, fmt='d', cmap='Blues')\n",
    "  plt.xticks(np.arange(len(languages)) + 0.5, languages, rotation= 45)\n",
    "  plt.yticks(np.arange(len(languages)) + 0.5, languages, rotation = 360)\n",
    "  plt.tight_layout()\n",
    "  plt.xlabel('Predicted')\n",
    "  plt.ylabel('Actual')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train and evaluate MNB model\n",
    "MNB_object = MultinomialNB()\n",
    "MNB_model = MNB_object.fit(x_train_vectorized, y_train)\n",
    "x_test_vectorized = vectorizer.transform(x_test)\n",
    "mnb_predicted = MNB_model.predict(x_test_vectorized)\n",
    "mnb_accuracy = accuracy_score(y_test, mnb_predicted)\n",
    "print(f\"Accuracy : {mnb_accuracy:.4f}\")\n",
    "confusion(mnb_predicted, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to check the accuracy and confusion matrix of the model on a dataframe of text\n",
    "'''def predict_dataset_MNB(dataset):\n",
    "  new_test_data = None\n",
    "  for ext in ['.csv', '.txt']:\n",
    "    try:\n",
    "      new_test_data = pd.read_csv(\"datasets\\\\\" + dataset + ext,   delimiter= \",\") \n",
    "      break #exit loop if file is found\n",
    "    except FileNotFoundError:\n",
    "      pass #continue to check next extension\n",
    "  if new_test_data is None:   #if file is not found\n",
    "      print('File not found')\n",
    "      return #exit function\n",
    "  new_data_x = new_test_data['text']\n",
    "  new_data_y = new_test_data['language']\n",
    "  new_data_vectorized = vectorizer.transform(new_data_x)\n",
    "  new_predictions_NB = MNB_model.predict(new_data_vectorized)\n",
    "  accuracy = accuracy_score(new_data_y, new_predictions_NB)\n",
    "  print(f\"Accuracy : {accuracy:.4f}\")\n",
    "  confusion(new_predictions_NB, new_data_y) '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to predict a single text\n",
    "'''def predict_text_MNB(text):\n",
    "    text = vectorizer.transform([text])\n",
    "    prediction = MNB_model.predict(text)\n",
    "    print(prediction) '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use function to check new dataset metrics\n",
    "'''predict_dataset_MNB('multilingual-100')\n",
    "predict_dataset_MNB('multilingual-sentences-dataset')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load new dataset and check metrics\n",
    "new_data_2 = pd.read_csv('multilingual-sentences-dataset.txt', delimiter=',')\n",
    "new_data_2.head()\n",
    "new_data_2_x = new_data_2['text']\n",
    "new_data_2_y = new_data_2['language']\n",
    "new_data_2_x_vectorized = vectorizer.transform(new_data_2_x)\n",
    "new_data_2_x_vectorized.shape\n",
    "new_data_2_predicted = MNB_model.predict(new_data_2_x_vectorized)\n",
    "new_accuracy = accuracy_score(new_data_2_y, new_data_2_predicted)\n",
    "print(f\"Accuracy : {new_accuracy:.4f}\")\n",
    "confusion(new_data_2_predicted, new_data_2_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataframe for misclassified languages\n",
    "new_df = pd.concat([new_data_2_x, new_data_2_y, pd.Series(new_data_2_predicted)], axis=1)\n",
    "new_df.columns = ['text','actual', 'predicted']\n",
    "errors_df = new_df[new_df['actual'] != new_df['predicted']]\n",
    "errors_df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
